\section{Related work}
\subsection{Detecting Factors of Forced Migration}
In 1997, Schmeidl \cite{schmeidl1997exploring} developed a theoretical model of refugee migration based on the factors with estimated magnitude. These factors include economical under-development, human rights violation, ethnic and civil conflicts. These factors were then included in a pooled time-series analysis to predict the number of refugees. This research showed that economic and intervening policy variables are less useful for predicting refugee migration than the threat of violence. This work is different from our model regarding the methodology used for extracting the forced migration signals. Unlike this research that uses manually generated scores from various resources for the factors mentioned above, we automatically extract the score of the factors of forced migration from news articles.

To analyze the trends of a particular topic over time, Wang et. al. introduced Topics over Time (TOT), which is an LDA-based topic model \cite{Wang2006}. To achieve this, they jointly model word co-occurrences and localization in continuous time windows. Furthermore, time-sensitive document topic modeling was proposed in [2], where the policies of the European Parliament (EP) are studied through dynamic topic modeling of the documents generated by the parliaments (e.g. debates and bills). Political agenda of the EP has evolved significantly over time as new events and topics unfold. 

The most similar research to ours was performed by Agrawal et al.\cite{agrawal2016detecting}. They introduced a method to extract the magnitude of violence from news articles. This method uses word embedding techniques to embed the words of news articles and then uses similarity measures within the embedding space to compute the similarity between the words of a document and a set of predefined seed words indicating violence. At last, a correlation was observed between the extracted violence scores and the number of migrated people. This work only detects the magnitude of violence from news articles and does not focus on other factors of forced migration. The quality of the extracted violence scores considerably depends on the quality of the manually generated set of seed words.

\subsection{Topic Modeling}
Topic modeling is an effective method to process large amount documents. The method allows for discovery of a distinct set of topics among the corpus. A topic modeling approach can connect the words with similar meaning and form topics.

\subsubsection{LDA (Latent Dirichlet Allocation)}
LDA belongs to the group of generative probabilistic models for documents. Based on an intuitive idea that each document is comprised of a mixture of topics, and each topic is a discrete probability distribution of how likely each word is to appear on a given topic. Given set of documents $W = \{w_1, w_2, ...,  w_d\}$, to generate a word token $w_n$  from document d, a discrete topic assignment $z_n$ is drawn from a document-specific distribution over the T topics $\theta_d$. This value is drawn from a Dirichlet prior with hyper-parameter $\alpha$. The inference task in topic models is defined as inferring the document proportions $\{\theta_1, ... \theta_D\}$ and the topic-specific distributions $\{\phi_1, ... ,  \phi_T\}$ \cite{Mimno}. 
Building on foundations of LDA, \cite{Griffiths} proposed using a Dirichlet prior on topic-word distribution $\phi$, with additional hyper-parameter $\beta$. Further, \cite{Griffiths} used collapsed Gibbs sampling to estimate the topic space distribution indirectly. This method iteratively estimates the probability assignment of each word to the topics, conditioned on the current topic assignment of all other words. The popular topic modeling toolkit MALLET is based on LDA with Gibbs sampling.
